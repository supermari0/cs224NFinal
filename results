0.56 something for 100 iterations with word features
0.547445255474 for 50 iterations with word + pos features
0.554744525547 for 50 iterations with word features
0.569343065693 for 50 iterations with top 2K word features
0.554744525547 for 100 iterations with top 2K word features
0.56204379562 for 25 iterations with top 2K word features
0.569343065693 for 50 iterations with top 2K word and 1K bigram features - WTF?
0.598540145985 for 50 iterations with 1K bigram features only
0.605839416058 for 75 iterations with 1K bigram features only
0.63503649635 for 75 iterations with 1.5K bigram features only
0.532846715328 for 75 iterations with 1.5K trigram features only


1.5K bigram features:
Accuracy: 0.63503649635
Precision: 0.594202898551
Recall: 0.650793650794

1.5K bigram features + bigram POS features:
Accuracy: 0.642335766423
Precision: 0.623188405797
Recall: 0.651515151515

1.5K bigram features + bigram POS features + trigram POS features:

- next: try binary POS trigram features. if that works, add bigram with backoff
